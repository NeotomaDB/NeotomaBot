{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter authenticated \n",
      "\n",
      "Files opened\n",
      "\n",
      "Neotoma welcomes another dataset: Greenbrier Lake from A.J. Smith, D.F. Palmer http://apps.neotomadb.org/Explorer/?datasetid=15823\n"
     ]
    },
    {
     "ename": "TweepError",
     "evalue": "Twitter error response: status code = 403",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b5d7b6b253f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mcheck_neotoma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m \u001b[0mpost_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-b5d7b6b253f2>\u001b[0m in \u001b[0;36mpost_tweet\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[1;31m#  Add the tweeted site to `old_files` and then delete it from the to_print.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python34\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mupdate_status\u001b[1;34m(self, media_ids, *args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mallowed_param\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in_reply_to_status_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'long'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'source'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'place_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'display_coordinates'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mrequire_auth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         )(post_data=post_data, *args, **kwargs)\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmedia_upload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python34\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;31m# Set pagination mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python34\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                     \u001b[0merror_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Twitter error response: status code = %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;31m# Parse the response payload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTweepError\u001b[0m: Twitter error response: status code = 403"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#!python3\n",
    "\n",
    "import tweepy, time, sys, json, requests, random\n",
    " \n",
    "def check_neotoma():\n",
    "    ## This function call to neotoma, reads a text file, compares the two\n",
    "    ## and then returns all the 'new' records to a different text file.\n",
    "\n",
    "    #  inputs:\n",
    "    #  1. text file: old_results.json\n",
    "    #  2. text file: to_print.json\n",
    "    #  3. json call: neotoma\n",
    "\n",
    "    with open('old_results.json', 'r') as old_file:\n",
    "        old_calls = json.loads(old_file.read())\n",
    "    \n",
    "    with open('to_print.json', 'r')    as print_file:\n",
    "        to_print  = json.loads(print_file.read())\n",
    "    \n",
    "    neotoma  = requests.get(\"http://ceiwin10.cei.psu.edu/NDB/RecentUploads?months=1\")\n",
    "    inp_json = json.loads(neotoma.text)['data']\n",
    "\n",
    "    def get_datasets(x):\n",
    "        did = []\n",
    "        for y in x:\n",
    "            did.append(y[\"DatasetID\"])\n",
    "        return did\n",
    "\n",
    "    neo_datasets = get_datasets(inp_json)\n",
    "    old_datasets = get_datasets(old_calls)\n",
    "    new_datasets = get_datasets(to_print)\n",
    "    \n",
    "    #  So this works\n",
    "    #  We now have the numeric dataset IDs for the most recent month of\n",
    "    #  new files to neotoma (neo_datasets), all the ones we've already tweeted\n",
    "    #  (old_datasets) and all the ones in our queue (new_datasets).\n",
    "    #\n",
    "    #  The next thing we want to do is to remove all the neo_datasets that\n",
    "    #  are in old_datasets and then remove all the new_datasets that are\n",
    "    #  in neo_datasets, append neo_datasets to new_datasets (if new_datasets\n",
    "    #  has a length > 0) and then dump new_datasets.\n",
    "    #\n",
    "    #  Old datasets gets re-written when the tweets go out.\n",
    "\n",
    "    #  remove all the neo_datasets:\n",
    "    for i in range(len(neo_datasets)-1, 0, -1):\n",
    "        if neo_datasets[i] in old_datasets:\n",
    "            del inp_json[i]\n",
    "\n",
    "    # This now gives us a pared down version of inp_json\n",
    "    # Now we need to make sure to add any of the to_print to neo_dataset.\n",
    "    #  We do this by cycling through new_datasets.  Any dataset number that\n",
    "    #  is not in old_datasets or neo_datasets gets added to the beginning of\n",
    "    #  the new list.  This way it is always the first called up when twitter\n",
    "    #  posts:\n",
    "    \n",
    "    for i in range(0, len(new_datasets)-1):\n",
    "        if new_datasets[i] not in old_datasets and new_datasets[i] not in neo_datasets:\n",
    "            inp_json.insert(0,to_print[i])\n",
    "\n",
    "    #  Now write out to file.  Old file doesn't get changed until the\n",
    "    #  twitter app is run.\n",
    "    with open('to_print.json', 'w')    as print_file:\n",
    "        json.dump(inp_json, print_file)\n",
    "\n",
    "def post_tweet():\n",
    "    CONSUMER_KEY = 'jou6H9DZLPzw6f3aSIY7wzC6n'\n",
    "    CONSUMER_SECRET = 'eum3NCrtrVC1tFsGvEj0GuqsxwQCWFfN8nmgcbMyA5xdmQhSdU'\n",
    "    ACCESS_KEY = '3184480124-AHNgg72lXKYEuOjyzh5WKzBMkBBejpKIX9OxKpX'\n",
    "    ACCESS_SECRET = 'GAmE6PX3ulj61tluwXA6jUKcPJwoCNToCg5JrJS8BbA3U'\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    print('Twitter authenticated \\n')\n",
    "        \n",
    "        # Read in the printable tweets:\n",
    "    with open('to_print.json', 'r') as print_file:\n",
    "        to_print  = json.loads(print_file.read())\n",
    "            \n",
    "    with open('old_results.json', 'r') as print_file:\n",
    "        old_files  = json.loads(print_file.read())\n",
    "        \n",
    "    print('Files opened\\n')\n",
    "        \n",
    "    #  Now loop through the records:\n",
    "    while len(to_print) > 0:\n",
    "        weblink = 'http://apps.neotomadb.org/Explorer/?datasetid=' + str(to_print[0][\"DatasetID\"])\n",
    "        \n",
    "        line = 'Neotoma welcomes another ' + to_print[0][\"DatabaseName\"] + ' dataset: ' + to_print[0][\"SiteName\"] + \" from \" + to_print[0][\"Investigator\"] + \" \" + weblink\n",
    "        \n",
    "        if len(line) > 170:\n",
    "            line = 'Neotoma welcomes another dataset: ' + to_print[0][\"SiteName\"] + \" from \" + to_print[0][\"Investigator\"] + \" \" + weblink\n",
    "                        \n",
    "        print('%s' % line)\n",
    "        \n",
    "        if random.randint(0,30) == 10:\n",
    "            line = 'This is a twitter bot for the Neotoma Paleoecological Database, letting you know what\\'s new. http://neotomadb.org managed by @sjgoring'\n",
    "            api.update_status(status=line)\n",
    "        else:\n",
    "            api.update_status(status=line)\n",
    "\n",
    "            #  Add the tweeted site to `old_files` and then delete it from the to_print.\n",
    "            old_files.append(to_print[0])\n",
    "\n",
    "            del to_print[0]\n",
    "\n",
    "            with open('to_print.json', 'w')    as print_file:\n",
    "                json.dump(to_print, print_file)\n",
    "\n",
    "            with open('old_results.json', 'w')    as print_file:\n",
    "                json.dump(old_files, print_file)\n",
    "\n",
    "        time.sleep(600) # Tweet every 10 minutes.\n",
    "        \n",
    "        if len(to_print) < 5:\n",
    "            check_neotoma()\n",
    "\n",
    "post_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy, time, sys, json, requests, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
